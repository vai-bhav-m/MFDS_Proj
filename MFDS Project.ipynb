{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ba45f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mughal Empire was founded by Babur, a Central Asian ruler, who reigned from 1526–1530. He descended from the Turco-Mongol conqueror Timur on his father's side, and from Genghis Khan on his mother's side.\n"
     ]
    }
   ],
   "source": [
    "ideal = \"The Mughal Empire was founded by Babur, a Central Asian ruler, who reigned from 1526–1530. He descended from the Turco-Mongol conqueror Timur on his father's side, and from Genghis Khan on his mother's side.\"\n",
    "print(ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9f0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d075a",
   "metadata": {},
   "source": [
    "Using Regex to first make a list of numbers in the best answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbaa39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1526', '1530']\n"
     ]
    }
   ],
   "source": [
    "numbers = re.sub(\"\\D\",\" \",ideal).split()\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5aac92",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7d0ea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mughal Empire was founded by Babur, a Central Asian ruler, who reigned from 1526–1530.\n",
      "\n",
      "He descended from the Turco-Mongol conqueror Timur on his father's side, and from Genghis Khan on his mother's side.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(ideal)\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a28151",
   "metadata": {},
   "source": [
    "Word Tokenizing using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e440da54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Mughal', 'Empire', 'was', 'founded', 'by', 'Babur', 'a', 'Central', 'Asian', 'ruler', 'who', 'reigned', 'from']\n",
      "\n",
      "['He', 'descended', 'from', 'the', 'Turco', 'Mongol', 'conqueror', 'Timur', 'on', 'his', 'father', 's', 'side', 'and', 'from', 'Genghis', 'Khan', 'on', 'his', 'mother', 's', 'side']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "for sentence in sentences:\n",
    "    words = re.sub(\"[^a-zA-Z]\",\" \",sentence).split()\n",
    "    print(words)\n",
    "    print()\n",
    "    word_list.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09326b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Mughal',\n",
       " 'Empire',\n",
       " 'founded',\n",
       " 'Babur',\n",
       " 'Central',\n",
       " 'Asian',\n",
       " 'ruler',\n",
       " 'reigned',\n",
       " 'He',\n",
       " 'descended',\n",
       " 'Turco',\n",
       " 'Mongol',\n",
       " 'conqueror',\n",
       " 'Timur',\n",
       " 'father',\n",
       " 'side',\n",
       " 'Genghis',\n",
       " 'Khan',\n",
       " 'mother',\n",
       " 'side']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [word for word in word_list if word not in set(stopwords.words('english'))]\n",
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b6db0",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization\n",
    "\n",
    "We'll lemmatize cuz it's more accurate than stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fef7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Mughal', 'Empire', 'found', 'Babur', 'Central', 'Asian', 'ruler', 'reign', 'He', 'descend', 'Turco', 'Mongol', 'conqueror', 'Timur', 'father', 'side', 'Genghis', 'Khan', 'mother', 'side']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemm_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in word_list]\n",
    "print(lemm_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620ea5e",
   "metadata": {},
   "source": [
    "Segregating proper nouns using **part of speech tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d169382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mughal', 'Empire', 'Babur', 'Central', 'Asian', 'Turco', 'Mongol', 'Timur', 'Genghis', 'Khan']\n"
     ]
    }
   ],
   "source": [
    "ppn_list = []\n",
    "tagged = nltk.pos_tag(lemm_words)\n",
    "for (word, tag) in tagged:\n",
    "    if tag == 'NNP': # If the word is a proper noun\n",
    "        ppn_list.append(word)\n",
    "print(ppn_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b41d461",
   "metadata": {},
   "source": [
    "Hence, we have made a list of the following attributes of ideal answer:\n",
    "1. Numbers\n",
    "2. Proper Nouns\n",
    "3. Common nouns and other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee4273b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of numbers:  ['1526', '1530']\n",
      "List of Proper Nouns:  ['Turco', 'Asian', 'Timur', 'Babur', 'Central', 'Genghis', 'Empire', 'Khan', 'Mongol', 'Mughal']\n",
      "List of Common Nouns and other words:  ['father', 'side', 'descend', 'reign', 'conqueror', 'ruler', 'mother', 'found']\n"
     ]
    }
   ],
   "source": [
    "ppn_list = list(set(ppn_list))\n",
    "cmn_list = [word.lower() for word in list(set(lemm_words) - set(ppn_list))]\n",
    "cmn_list = [word for word in cmn_list if word not in set(stopwords.words('english'))]\n",
    "num_list = list(set(numbers))\n",
    "\n",
    "print(\"List of numbers: \", num_list)\n",
    "print(\"List of Proper Nouns: \", ppn_list)\n",
    "print(\"List of Common Nouns and other words: \", cmn_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01d9f2",
   "metadata": {},
   "source": [
    "Defining a single function representing all transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134bfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_attributes(answer):\n",
    "    num_list = list(set(re.sub(\"\\D\",\" \",answer).split()))\n",
    "    \n",
    "    # Sentence Tokenization\n",
    "    sentences = nltk.sent_tokenize(answer)\n",
    "    # Word Tokenization with Regex\n",
    "    word_list = []\n",
    "    for sentence in sentences:\n",
    "        words = re.sub(\"[^a-zA-Z]\",\" \",answer).split()\n",
    "        words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "        word_list.extend(words)\n",
    "    \n",
    "    # Lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in word_list]\n",
    "    \n",
    "    # Segregating Proper Nouns\n",
    "    ppn_list = []\n",
    "    tagged = nltk.pos_tag(lemm_words)\n",
    "    for (word, tag) in tagged:\n",
    "        if tag == 'NNP': # If the word is a proper noun\n",
    "            ppn_list.append(word)\n",
    "    ppn_list = list(set(ppn_list))\n",
    "    \n",
    "    # Segregating Common Nouns and other words\n",
    "    cmn_list = [word.lower() for word in list(set(lemm_words) - set(ppn_list))]\n",
    "    cmn_list = [word for word in cmn_list if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    return num_list, ppn_list, cmn_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdc890",
   "metadata": {},
   "source": [
    "## Vectorizing and grading an Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a854a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt = \"The Mughal Empire was founded by Babur, an Asian ruler, who reigned till 1530. He descended from Timur on his father's side, and from Genghis Khan on his mother's side.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6852ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightage = [0.5, 0.3, 0.2]  # Weightage split of 5:3:2 between proper_nouns : numbers : common_nouns\n",
    "\n",
    "def vectoriser(ideal, attempt):\n",
    "    ideal_vec = [1, 1, 1, 1]\n",
    "    attempt_vec = [1, 0, 1, 1]\n",
    "    return ideal_vec, attempt_vec\n",
    "\n",
    "def scoreit(ideal_vec, attempt_vec):\n",
    "    \n",
    "    pass\n",
    "\n",
    "ppn_vec_ideal, ppn_vec_attempt = vectoriser(answer_attributes(ideal)[1], answer_attributes(attempt)[1])\n",
    "ppn_score = scoreit(ppn_vec_ideal, ppn_vec_attempt)\n",
    "\n",
    "num_vec_ideal, num_vec_attempt = vectoriser(answer_attributes(ideal)[0], answer_attributes(attempt)[0])\n",
    "num_score = scoreit(num_vec_ideal, num_vec_attempt)\n",
    "\n",
    "cmn_vec_ideal, cmn_vec_attempt = vectoriser(answer_attributes(ideal)[2], answer_attributes(attempt)[2])\n",
    "cmn_score = scoreit(cmn_vec_ideal, cmn_vec_attempt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4589b",
   "metadata": {},
   "source": [
    "Final Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad49a2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-92b97dc213cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweightage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mppn_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mweightage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mweightage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcnn_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Final Score (out of 100) = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFinal\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "Final = weightage[0] * ppn_score + weightage[1] * num_score + weightage[2] * cnn_score \n",
    "print(\"Final Score (out of 100) = \", Final * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd33c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
