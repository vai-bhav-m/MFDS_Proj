{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d36140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e00c1",
   "metadata": {},
   "source": [
    "# Demonstration on a test case:\n",
    "Initializing the instructor's template and student's answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec2f312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mughal Empire was founded by Babur, a Central Asian ruler, who reigned from 1526–1530. He descended from the Turco-Mongol conqueror Timur on his father's side, and from Genghis Khan on his mother's side.\n",
      "The Mughal Empire was founded by Babur, an Asian ruler, who reigned till 1530. He descended from Timur on his father's side, and from Genghis Khan on his mother's side.\n"
     ]
    }
   ],
   "source": [
    "ideal = \"The Mughal Empire was founded by Babur, a Central Asian ruler, who reigned from 1526–1530. He descended from the Turco-Mongol conqueror Timur on his father's side, and from Genghis Khan on his mother's side.\"\n",
    "attempt = \"The Mughal Empire was founded by Babur, an Asian ruler, who reigned till 1530. He descended from Timur on his father's side, and from Genghis Khan on his mother's side.\"\n",
    "print(ideal)\n",
    "print(attempt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe0f51",
   "metadata": {},
   "source": [
    "The instructor's template string is used here to demonstrate the processing techniques that are implemented in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc7fc5",
   "metadata": {},
   "source": [
    "Using Regex to first make a list of numbers in the best answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a40ac5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1526', '1530']\n"
     ]
    }
   ],
   "source": [
    "numbers = re.sub(\"\\D\",\" \",ideal).split() # Identifies and lists the occurrences of numbericals in the sentences\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf79ad",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16edadff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mughal Empire was founded by Babur, a Central Asian ruler, who reigned from 1526–1530.\n",
      "\n",
      "He descended from the Turco-Mongol conqueror Timur on his father's side, and from Genghis Khan on his mother's side.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(ideal) # Seperates the sentences in the given string\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f445f1c",
   "metadata": {},
   "source": [
    "Word Tokenizing using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b377986e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Mughal', 'Empire', 'was', 'founded', 'by', 'Babur', 'a', 'Central', 'Asian', 'ruler', 'who', 'reigned', 'from']\n",
      "\n",
      "['He', 'descended', 'from', 'the', 'Turco', 'Mongol', 'conqueror', 'Timur', 'on', 'his', 'father', 's', 'side', 'and', 'from', 'Genghis', 'Khan', 'on', 'his', 'mother', 's', 'side']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "for sentence in sentences:\n",
    "    words = re.sub(\"[^a-zA-Z]\",\" \",sentence).split()\n",
    "    print(words)\n",
    "    print()\n",
    "    word_list.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df43194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sriram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords') # Uncomment and run if 'stopwords' is not downloaded previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5d0eefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Mughal', 'Empire', 'founded', 'Babur', 'Central', 'Asian', 'ruler', 'reigned', 'He', 'descended', 'Turco', 'Mongol', 'conqueror', 'Timur', 'father', 'side', 'Genghis', 'Khan', 'mother', 'side']\n"
     ]
    }
   ],
   "source": [
    "# Stop words Removal\n",
    "\n",
    "word_list = [word for word in word_list if word not in set(stopwords.words('english'))]\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728ec8e",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization\n",
    "\n",
    "Lemmatization is usually more accurate and effective than stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de909129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sriram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('wordnet') # Uncomment and run if 'wordnet' is not downloaded previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da619ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Mughal', 'Empire', 'found', 'Babur', 'Central', 'Asian', 'ruler', 'reign', 'He', 'descend', 'Turco', 'Mongol', 'conqueror', 'Timur', 'father', 'side', 'Genghis', 'Khan', 'mother', 'side']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemm_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in word_list]\n",
    "print(lemm_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413f357",
   "metadata": {},
   "source": [
    "Segregating proper nouns using **part of speech tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4811cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sriram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('averaged_perceptron_tagger') # # Uncomment and run if 'averaged_perceptron_tagger' is not downloaded previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "390aa02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mughal', 'Empire', 'Babur', 'Central', 'Asian', 'Turco', 'Mongol', 'Timur', 'Genghis', 'Khan']\n"
     ]
    }
   ],
   "source": [
    "# Demonstration on identifying proper nouns in the string\n",
    "\n",
    "ppn_list = []\n",
    "tagged = nltk.pos_tag(lemm_words)\n",
    "for (word, tag) in tagged:\n",
    "    if tag == 'NNP': # If the word is a proper noun\n",
    "        ppn_list.append(word)\n",
    "print(ppn_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5614641",
   "metadata": {},
   "source": [
    "Hence, we have made a list of the following attributes of ideal answer:\n",
    "1. Numbers\n",
    "2. Proper Nouns\n",
    "3. Common nouns and other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d597866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of numbers:  ['1530', '1526']\n",
      "List of Proper Nouns:  ['Mughal', 'Central', 'Genghis', 'Turco', 'Khan', 'Timur', 'Asian', 'Babur', 'Empire', 'Mongol']\n",
      "List of Common Nouns and other words:  ['ruler', 'side', 'father', 'reign', 'mother', 'conqueror', 'found', 'descend']\n"
     ]
    }
   ],
   "source": [
    "# Demonstration on identifying proper nouns, common nouns and numericals in the string\n",
    "\n",
    "ppn_list = list(set(ppn_list))\n",
    "cmn_list = [word.lower() for word in list(set(lemm_words) - set(ppn_list))]\n",
    "cmn_list = [word for word in cmn_list if word not in set(stopwords.words('english'))]\n",
    "num_list = list(set(numbers))\n",
    "\n",
    "print(\"List of numbers: \", num_list)\n",
    "print(\"List of Proper Nouns: \", ppn_list)\n",
    "print(\"List of Common Nouns and other words: \", cmn_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a23ed",
   "metadata": {},
   "source": [
    "# Defining a single function representing all transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a337bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_attributes_ideal(answer):\n",
    "    num_list = list(set(re.sub(\"\\D\",\" \",answer).split()))\n",
    "    \n",
    "    # Sentence Tokenization\n",
    "    sentences = nltk.sent_tokenize(answer)\n",
    "    # Word Tokenization with Regex\n",
    "    word_list = []\n",
    "    for sentence in sentences:\n",
    "        words = re.sub(\"[^a-zA-Z]\",\" \",answer).split()\n",
    "        words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "        word_list.extend(words)\n",
    "    \n",
    "    # Lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in word_list]\n",
    "    \n",
    "    # Segregating Proper Nouns\n",
    "    ppn_list = []\n",
    "    tagged = nltk.pos_tag(lemm_words)\n",
    "    for (word, tag) in tagged:\n",
    "        if tag == 'NNP': # If the word is a proper noun\n",
    "            ppn_list.append(word)\n",
    "    ppn_list = list(set(ppn_list))\n",
    "    \n",
    "    # Segregating Common Nouns and other words\n",
    "    cmn_list = [word.lower() for word in list(set(lemm_words) - set(ppn_list))]\n",
    "    cmn_list = [word for word in cmn_list if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    return num_list, ppn_list, cmn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75f3cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_attributes_attempt(correct_cmnlist, answer):\n",
    "    num_list = list(set(re.sub(\"\\D\",\" \",answer).split()))\n",
    "    \n",
    "    # Sentence Tokenization\n",
    "    sentences = nltk.sent_tokenize(answer)\n",
    "    # Word Tokenization with Regex\n",
    "    word_list = []\n",
    "    for sentence in sentences:\n",
    "        words = re.sub(\"[^a-zA-Z]\",\" \",answer).split()\n",
    "        words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "        word_list.extend(words)\n",
    "    \n",
    "    # Lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in word_list]\n",
    "    \n",
    "    # Segregating Proper Nouns\n",
    "    ppn_list = []\n",
    "    tagged = nltk.pos_tag(lemm_words)\n",
    "    for (word, tag) in tagged:\n",
    "        if tag == 'NNP': # If the word is a proper noun\n",
    "            ppn_list.append(word)\n",
    "    ppn_list = list(set(ppn_list))\n",
    "    \n",
    "    # Segregating Common Nouns and other words\n",
    "    cmn_list = [word.lower() for word in list(set(lemm_words) - set(ppn_list))]\n",
    "    cmn_list = [word for word in cmn_list if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    # Synonym matching for common nouns using synsets\n",
    "    for word in correct_cmnlist:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for i in syn.lemmas():\n",
    "                for k in range(len(cmn_list)):\n",
    "                    if i.name() == cmn_list[k]:\n",
    "                        cmn_list[k] = word\n",
    "\n",
    "    return num_list, ppn_list, cmn_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ea05c",
   "metadata": {},
   "source": [
    "## Vectorizing and grading an Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55781a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectoriser(ideal, attempt):\n",
    "    word_set = list(set(ideal).union(set(attempt)))\n",
    "\n",
    "    word_count_ideal = {}\n",
    "    word_count_attempt = {}\n",
    "    for word in word_set:\n",
    "        word_count_ideal[word] = 0\n",
    "        word_count_attempt[word] = 0\n",
    "    for word in ideal:\n",
    "        word_count_ideal[word] += 1\n",
    "    for word in attempt:\n",
    "        word_count_attempt[word] += 1\n",
    "\n",
    "    return list(word_count_ideal.values()),list(word_count_attempt.values())\n",
    "\n",
    "def scoreit(ideal_vec, attempt_vec):\n",
    "    sim = np.dot(ideal_vec, attempt_vec)\n",
    "    if sim != 0:\n",
    "        sim = sim / (norm(ideal_vec)*norm(attempt_vec))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aeb3e6",
   "metadata": {},
   "source": [
    "# The Grader function\n",
    "This function makes use of all the functions above and prints the similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a32f5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grader(ideal, attempt, weightage = [0.5,0.3,0.2]): # Different weights for proper nouns, common nouns and numbers\n",
    "    ppn_vec_ideal, ppn_vec_attempt = vectoriser(answer_attributes_ideal(ideal)[1], answer_attributes_ideal(attempt)[1])\n",
    "    ppn_score = scoreit(ppn_vec_ideal, ppn_vec_attempt)\n",
    "\n",
    "    num_vec_ideal, num_vec_attempt = vectoriser(answer_attributes_ideal(ideal)[0], answer_attributes_ideal(attempt)[0])\n",
    "    num_score = scoreit(num_vec_ideal, num_vec_attempt)\n",
    "\n",
    "    cmn_vec_ideal, cmn_vec_attempt = vectoriser(answer_attributes_ideal(ideal)[2], answer_attributes_attempt(answer_attributes_ideal(ideal)[2],attempt)[2])\n",
    "    cmn_score = scoreit(cmn_vec_ideal, cmn_vec_attempt)\n",
    "    \n",
    "    Final = weightage[0] * ppn_score + weightage[1] * num_score + weightage[2] * cmn_score\n",
    "    print(\"Final Score (out of 100) = \", Final * 100)\n",
    "    return # Final*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a223e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score (out of 100) =  78.69868060479874\n"
     ]
    }
   ],
   "source": [
    "grader(ideal,attempt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410dcd0",
   "metadata": {},
   "source": [
    "# Test cases\n",
    "These are the results on 5 manually generated test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efa51487",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal1 = \"KGF is one of the best movies if not the best movie ever made in the kannada film history. It is a recent film packed with lots of adventures and emotions. It has collected a lump sum of 1200 crores box office collection worldwide and stands in top 5 of India's highest grossed movies. Lead roles of the film were played by Yash,Srinidhi and Sanjay.\"\n",
    "attempt1 = \"KGF is a recent released movie which can be considered one of the best movies if not the best ever made in the kannada film history. It's packed with lots of adventures and emotions. It has collected a large sum of 1200 crores in the box office collection worldwide and it stands in the top 5 highest grossing movies of Indian cinema. Lead roles of the film were played by Yash,Srinidhi and Sanjay.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf1e1d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KGF is one of the best movies if not the best movie ever made in the kannada film history. It is a recent film packed with lots of adventures and emotions. It has collected a lump sum of 1200 crores box office collection worldwide and stands in top 5 of India's highest grossed movies. Lead roles of the film were played by Yash,Srinidhi and Sanjay.\n",
      "KGF is a recent released movie which can be considered one of the best movies if not the best ever made in the kannada film history. It's packed with lots of adventures and emotions. It has collected a large sum of 1200 crores in the box office collection worldwide and it stands in the top 5 highest grossing movies of Indian cinema. Lead roles of the film were played by Yash,Srinidhi and Sanjay.\n",
      "Final Score (out of 100) =  86.44216614641168\n"
     ]
    }
   ],
   "source": [
    "print(ideal1)\n",
    "print(attempt1)\n",
    "grader(ideal1,attempt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf4503d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal2 = \"IITM is said to be one of the best colleges, nevertheless there are a lot of management issues and is deemed by its students as one of the worst colleges. Its main strength is the alumni base and the student resource which over the years has given it laurels and hence the award NIRF 1\"\n",
    "attempt2 = \"IIT madras is not a great college, everytime one has been to it he suffers from depression. The only thing that keeps one going is the placement and the packages if not no one would want to go for it. It did get nirf 1 award but it's all a scam and been manipulated by the administration. Lot of management problems and nothing is done on time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81f4ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IITM is said to be one of the best colleges, nevertheless there are a lot of management issues and is deemed by its students as one of the worst colleges. Its main strength is the alumni base and the student resource which over the years has given it laurels and hence the award NIRF 1\n",
      "IIT madras is not a great college, everytime one has been to it he suffers from depression. The only thing that keeps one going is the placement and the packages if not no one would want to go for it. It did get nirf 1 award but it's all a scam and been manipulated by the administration. Lot of management problems and nothing is done on time.\n",
      "Final Score (out of 100) =  33.481553119113954\n"
     ]
    }
   ],
   "source": [
    "print(ideal2)\n",
    "print(attempt2)\n",
    "grader(ideal2,attempt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a81987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal3 = \"Life is a precious commodity, live it fully and enjoy every moment of it. As everyone says - YOLO, you only live once! There are a lot of things that can be done in life, meeting new people and sharing experiences is the best thing to bring one happiness and keeps everyone involved mentally healthy. The second part is the body - little excercise a day keeps the body healthy. Finally the soul, one’s inner self - explore yourself, you’ll feel your soul.\"\n",
    "attempt3 = \"Life is equivalent to death. One should not live it fully and not enjoy it. There are a lot of things which if done in life such as meeting new people will make you dead mentally. The same with one’s body, excerise is never healthy if done daily. Soul is just a myth - there is nothgin called an inner self, so do no explore yourself. You can never feel your soul as it does not exist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54a28c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life is a precious commodity, live it fully and enjoy every moment of it. As everyone says - YOLO, you only live once! There are a lot of things that can be done in life, meeting new people and sharing experiences is the best thing to bring one happiness and keeps everyone involved mentally healthy. The second part is the body - little excercise a day keeps the body healthy. Finally the soul, one’s inner self - explore yourself, you’ll feel your soul.\n",
      "Life is equivalent to death. One should not live it fully and not enjoy it. There are a lot of things which if done in life such as meeting new people will make you dead mentally. The same with one’s body, excerise is never healthy if done daily. Soul is just a myth - there is nothgin called an inner self, so do no explore yourself. You can never feel your soul as it does not exist.\n",
      "Final Score (out of 100) =  31.080029464446447\n"
     ]
    }
   ],
   "source": [
    "print(ideal3)\n",
    "print(attempt3)\n",
    "grader(ideal3,attempt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "32eac599",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal4 = \"Evaporation happens when a liquid turns into a gas. It can be easily visualized when rain puddles “disappear” on a hot day or when wet clothes dry in the sun. In these examples, the liquid water is not actually vanishing—it is evaporating into a gas, called water vapor. Evaporation happens on a global scale.\"\n",
    "attempt4 = \"Evaporation is a process where liquids change to a gas or vapor. Water changes to a vapor or steam from the energy created when molecules bounce into one another because they're heated up. Sweat drying from our body is a great example of evaporation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85801edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaporation happens when a liquid turns into a gas. It can be easily visualized when rain puddles “disappear” on a hot day or when wet clothes dry in the sun. In these examples, the liquid water is not actually vanishing—it is evaporating into a gas, called water vapor. Evaporation happens on a global scale.\n",
      "Evaporation is a process where liquids change to a gas or vapor. Water changes to a vapor or steam from the energy created when molecules bounce into one another because they're heated up. Sweat drying from our body is a great example of evaporation.\n",
      "Final Score (out of 100) =  33.43186810535768\n"
     ]
    }
   ],
   "source": [
    "print(ideal4)\n",
    "print(attempt4)\n",
    "grader(ideal4,attempt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8dedb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal5 = \"The assassination of Austrian Archduke Franz Ferdinand (June 28, 1914) was the main catalyst for the start of the Great War (World War I)\"\n",
    "attempt5 = \"The main catalyst of world war I is killing of Archduke Franz Ferdinand on June 28, 1914.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24b6642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The assassination of Austrian Archduke Franz Ferdinand (June 28, 1914) was the main catalyst for the start of the Great War (World War I)\n",
      "The main catalyst of world war I is killing of Archduke Franz Ferdinand on June 28, 1914.\n",
      "Final Score (out of 100) =  74.29961096932652\n"
     ]
    }
   ],
   "source": [
    "print(ideal5)\n",
    "print(attempt5)\n",
    "grader(ideal5,attempt5)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
